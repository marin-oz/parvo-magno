# On the emergence of the parvo-magno distinction: Potential role of developmental experience

This repository contains the code for the paper "On the emergence of the parvo-magno distinction: Potential role of developmental experience" (under review).

## Datasets used in this project

### ImageNet
https://www.image-net.org/index.php

Deng, J., Dong, W., Socher, R., Li, L. J., Li, K., & Fei-Fei, L. (2009, June). Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition (pp. 248-255). Ieee.

### Texture vs Shape
https://github.com/rgeirhos/texture-vs-shape

Geirhos, R., Rubisch, P., Michaelis, C., Bethge, M., Wichmann, F. A., & Brendel, W. (2018). ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. arXiv preprint arXiv:1811.12231.

### Kinetics600

Carreira, J., Noland, E., Banki-Horvath, A., Hillier, C., & Zisserman, A. (2018). A short note about kinetics-600. arXiv preprint arXiv:1808.01340.

## Project structure

```
parvo-magno/
├── LICENSE
├── README.md
├── requirements.txt
├── imageNet <- Contains resources for 2D CNNs results
│   ├── data <- Contains the class matching file
│   ├── figures <- Contains the figure pngs for the paper
│   ├── notebooks <- Notebooks for generating figures
│   ├── result <- Contains testing result csvs
│   ├── src <- Source code for training and testing
│   └── trained_models (not on GitHub; Google Drive link below)
├── kinetics600 <- Contains resources for 3D CNNs results
│   ├── figures <- Contains the figure pngs for the paper
│   ├── notebooks <- Notebooks for generating figures
│   ├── src <- Source code for training and testing
│   └── trained_models (not on GitHub; Google Drive link below)
```

## ImageNet
### data
Contains the matching between 1000 ImageNet classes and texture vs shape 16 categories. (Generated using the `imageNet/src/prep_texture.py` script.)
### figures
The figures for the 2D CNN part are in the `imageNet/figures` folder.
These can be generated by running the notebooks in the `imageNet/notebooks` folder.

### result
The result csvs for the 2D CNN part are in the `imageNet/result` folder.
These can be generated by running `imageNet/src/run_test.py`

### src
The source code for the 2D CNN part is in the `imageNet/src` folder.

### trained_models
All trained models for the 2D CNN part are in the `imageNet/trained_models` folder.
Trained models can be found [here](https://drive.google.com/drive/folders/1OreAi8FAXofSR1XqGMPoOOI5xKstYrRQ?usp=share_link) (Google Drive link; will be permanently deposited on Zenodo upon publication).

## kinetics600
### figures
The figures for the 3D CNN part are in the `kinetics600/figures` folder.
These can be generated by running the notebook in the `kinetics600/notebooks` folder.

### src
The source code for the 3D CNN part is in the `kinetics600/src` folder.

### trained_models
The trained models for the 3D CNN part are in the `kinetics600/trained_models` folder.
Trained models can be found [here](https://drive.google.com/drive/folders/1OreAi8FAXofSR1XqGMPoOOI5xKstYrRQ?usp=share_link) (Google Drive link; will be permanently deposited on Zenodo upon publication).

## Subdirectory structure

trained_models, result, figures follow the following general structure:

```
trained_models or result or figures/
├── (model_name)/
│   ├── (param_version)/
│   │   ├── (repetition_idx)/
│   │   └── ...
│   └── ...
```

model_name: alexnet22_48 (48 22x22 RFS; setting 1, 4, 5), alexnet22 (96 22x22 RFS; setting 2), alexnet (96 11x11 RFS; setting 3), alexnet22_48_half (biomimetic v4 within setting 1)

param_version: 0 (constant learning rate), 1 (decreasing learning rate)

repetition_idx: 0, 1, 2, 3, 4 (5 repetitions with different random seeds)

## Explanation of different training settings for 2D CNN part

Given the above structure, the different training settings described in the manuscript thus correspond to:

Setting 1 (48 22x22 RFs):

-     Biomimetic:    alexnet22_48/0/*/g4-100_c0-100
-     Standard:      alexnet22_48/0/*/c0-100_c0-100
-     Biomimetic v2  alexnet22_48/0/*/g4-050_c4-050_c0-100
-     Biomimetic v3  alexnet22_48/0/*/g4-100_c0-100_c0-100
-     Biomimetic v4  alexnet22_48_half/0/*/g4-100_c0-100

Setting 2 (96 22x22 RFs):

-     Biomimetic:    alexnet22/0/*/g4-100_c0-100
-     Standard:      alexnet22/0/*/c0-100_c0-100

Setting 3 (96 11x11 RFs):

-     Biomimetic:    alexnet/0/*/g4-100_c0-100
-     Standard:      alexnet/0/*/c0-100_c0-100

Setting 4 (setting 1 but using 100 instead of 200 epochs):

-     Biomimetic:    alexnet22_48/0/*/g4-50_c0-50
-     Standard:      alexnet22_48/0/*/c0-50_c0-50

Setting 5 (setting 1 but using a decreasing learning rate):

-     Biomimetic:    alexnet22_48/1/*/g4-100_c0-100
-     Standard:      alexnet22_48/1/*/c0-100_c0-100

The “g4-100_c0-100“ for the biomimetic model thereby describes training on grayscale images with blur 4 for 100 epochs, followed by training on color images with blur 0 for 100 epochs.
